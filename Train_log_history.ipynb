{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from libs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'google-bert/bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=19, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_k_accuracy(preds, labels, k=1):\n",
    "    top_k_preds = np.argsort(preds, axis=1)[:, -k:]\n",
    "    top_k_accuracy = np.any(top_k_preds == np.expand_dims(labels, axis=1), axis=1).mean()\n",
    "    return top_k_accuracy\n",
    "\n",
    "def preprocess_function(examples, tokenizer):\n",
    "    return tokenizer(examples[\"Question\"], truncation=True, padding = 'max_length', max_length=512)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42e81bd1e5d4d3c9d57d4ab1202bd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/62 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b5d587a5954356a8fa743d372da041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/73 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 42\n",
    "df_test_asdiv = pd.read_csv(f'data_first_ver/{seed}_test_set_asdiv.csv')\n",
    "df_test_mcas = pd.read_csv(f'data_first_ver/{seed}_test_set_mcas.csv')\n",
    "\n",
    "dataset_test_asdiv = Dataset.from_pandas(df_test_asdiv)\n",
    "dataset_test_mcas = Dataset.from_pandas(df_test_mcas)\n",
    "\n",
    "tokenized_dataset_test_asdiv = dataset_test_asdiv.map(lambda x: preprocess_function(x, tokenizer), batched=True)\n",
    "tokenized_dataset_test_mcas = dataset_test_mcas.map(lambda x: preprocess_function(x, tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lehai\\anaconda3\\envs\\temasek_genAI\\lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on test set for seed 42...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0012e37773dd478c84a8b8c51d942619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de49ace8cfc94bd28bb7ef7938ce2c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASDIV: {'eval_loss': 3.0698134899139404, 'eval_runtime': 35.5289, 'eval_samples_per_second': 1.745, 'eval_steps_per_second': 1.745}\n",
      "MCAS: {'eval_loss': 2.979890823364258, 'eval_runtime': 40.0275, 'eval_samples_per_second': 1.824, 'eval_steps_per_second': 1.824}\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        per_device_eval_batch_size= 1,\n",
    "        output_dir= './result'\n",
    "    ),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=None\n",
    ")\n",
    "\n",
    "print(f\"Evaluation on test set for seed {seed}...\")\n",
    "test_results_asdiv = trainer.evaluate(eval_dataset=tokenized_dataset_test_asdiv)\n",
    "test_results_mcas = trainer.evaluate(eval_dataset=tokenized_dataset_test_mcas)\n",
    "print(f'ASDIV: {test_results_asdiv}')\n",
    "print(f'MCAS: {test_results_mcas}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daba7395227042eab4001cb06ef3e3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e55c1778d15432aa482c7945bceb92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_asdiv = trainer.predict(tokenized_dataset_test_asdiv).predictions\n",
    "labels_asdiv = np.array(tokenized_dataset_test_asdiv[\"label\"])\n",
    "\n",
    "preds_mcas = trainer.predict(tokenized_dataset_test_mcas).predictions\n",
    "labels_mcas = np.array(tokenized_dataset_test_mcas[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_asdiv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11436419,  0.40059042,  0.33430475, ...,  0.23638973,\n",
       "        -0.2792644 ,  0.17329365],\n",
       "       [ 0.14490099,  0.30057898,  0.33392623, ...,  0.25265345,\n",
       "        -0.27043825,  0.2187818 ],\n",
       "       [ 0.14490099,  0.30057898,  0.33392623, ...,  0.25265345,\n",
       "        -0.27043825,  0.2187818 ],\n",
       "       ...,\n",
       "       [ 0.08702233,  0.3386045 ,  0.2955528 , ...,  0.22843863,\n",
       "        -0.27322516,  0.1883105 ],\n",
       "       [ 0.08702233,  0.3386045 ,  0.2955528 , ...,  0.22843863,\n",
       "        -0.27322516,  0.1883105 ],\n",
       "       [ 0.09362254,  0.35367736,  0.2959504 , ...,  0.19492975,\n",
       "        -0.29393795,  0.19146667]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_asdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.expand_dims(labels_asdiv, axis=1) == np.argsort(preds_asdiv, axis=1)[:, -18:], axis = 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_asdiv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5],\n",
       "       [ 3],\n",
       "       [15],\n",
       "       [ 2],\n",
       "       [18],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 4],\n",
       "       [ 6],\n",
       "       [ 3],\n",
       "       [14],\n",
       "       [13],\n",
       "       [10],\n",
       "       [16],\n",
       "       [16],\n",
       "       [14],\n",
       "       [12],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [18],\n",
       "       [ 4],\n",
       "       [17],\n",
       "       [ 3],\n",
       "       [ 1],\n",
       "       [12],\n",
       "       [ 4],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [13],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 9],\n",
       "       [ 0],\n",
       "       [ 2],\n",
       "       [10],\n",
       "       [14],\n",
       "       [10],\n",
       "       [14],\n",
       "       [ 2],\n",
       "       [ 5],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [10],\n",
       "       [ 0],\n",
       "       [ 7],\n",
       "       [18],\n",
       "       [ 3],\n",
       "       [ 7],\n",
       "       [13],\n",
       "       [18],\n",
       "       [ 3],\n",
       "       [11],\n",
       "       [ 8],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       [ 3],\n",
       "       [10],\n",
       "       [12],\n",
       "       [ 0],\n",
       "       [15]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(labels_asdiv, axis=1) # Change to shape (62,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5]\n",
      " [ 3]\n",
      " [15]\n",
      " [ 2]\n",
      " [18]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [ 6]\n",
      " [ 3]\n",
      " [14]\n",
      " [13]\n",
      " [10]\n",
      " [16]\n",
      " [16]\n",
      " [14]\n",
      " [12]\n",
      " [ 3]\n",
      " [ 3]\n",
      " [18]\n",
      " [ 4]\n",
      " [17]\n",
      " [ 3]\n",
      " [ 1]\n",
      " [12]\n",
      " [ 4]\n",
      " [ 7]\n",
      " [ 7]\n",
      " [ 4]\n",
      " [ 3]\n",
      " [13]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 9]\n",
      " [ 0]\n",
      " [ 2]\n",
      " [10]\n",
      " [14]\n",
      " [10]\n",
      " [14]\n",
      " [ 2]\n",
      " [ 5]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [10]\n",
      " [ 0]\n",
      " [ 7]\n",
      " [18]\n",
      " [ 3]\n",
      " [ 7]\n",
      " [13]\n",
      " [18]\n",
      " [ 3]\n",
      " [11]\n",
      " [ 8]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 3]\n",
      " [10]\n",
      " [12]\n",
      " [ 0]\n",
      " [15]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06451612903225806"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_k_predictions(predictions, k=1):\n",
    "    top_k_preds = np.argsort(predictions, axis=1)[:, -k:]\n",
    "    return top_k_preds\n",
    "\n",
    "def compute_top_k_accuracy(preds, labels, k=1):\n",
    "    top_k_preds = np.argsort(preds, axis=1)[:, -k:]\n",
    "    top_k_accuracy = np.any(top_k_preds == np.expand_dims(labels, axis=1), axis=1).mean()\n",
    "    print(np.expand_dims(labels, axis=1))\n",
    "    return top_k_accuracy\n",
    "\n",
    "\n",
    "compute_top_k_accuracy(preds_asdiv, labels_asdiv, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967741935483871"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_top_k_accuracy(preds_asdiv, labels_asdiv, k=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1, 4):\n",
    "        top_k_accuracies_asdiv[k] += compute_top_k_accuracy(preds_asdiv, labels_asdiv, k=k)\n",
    "        top_k_accuracies_mcas[k] += compute_top_k_accuracy(preds_mcas, labels_mcas, k=k)\n",
    "\n",
    "results = []\n",
    "results.append([f\"Seed {seed}\", test_results_asdiv['eval_accuracy'], test_results_mcas['eval_accuracy']])\n",
    "test_acc_asdiv += test_results_asdiv['eval_accuracy']\n",
    "test_acc_mcas += test_results_mcas['eval_accuracy']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
